{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb24a1ab-b3b3-4e12-9522-fb5d1ae68888",
   "metadata": {},
   "source": [
    "## AE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99702c9c-00b6-45be-b84c-b785a2b70a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a8931393-d25e-42ee-a2a6-79754bd36a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# struktura sieci neuronowej\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    Implementation of multi layer perceptron\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    model_type : str\n",
    "        model type, regressor or classifier\n",
    "    layers : List\n",
    "        list of layer sizes\n",
    "    num_layers : int\n",
    "        number of layers\n",
    "    init_function : func\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers, X, y, initalization='xavier', model_type='regression', weights=None, biases=None, activations=None):\n",
    "        \"\"\"\n",
    "        activations - list of available functions: 'sigmoid', 'linear', 'tanh', 'relu', 'softmax' ('softmax' can be used only on the last layer)\n",
    "        initialization - available types: 'xavier', 'he', 'uniform'\n",
    "        model_type - available types: 'regression', 'classification'\n",
    "        \"\"\"        \n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        if model_type == 'regression':\n",
    "            X = X.to_numpy().reshape(-1, 1)\n",
    "            y = y.to_numpy().reshape(-1, 1)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        initialization_functions = {\n",
    "            'xavier': self.xavier_init,\n",
    "            'he': self.he_init,\n",
    "            'uniform': self.uniform_init\n",
    "        }\n",
    "        self.init_function = initialization_functions.get(initalization)\n",
    "        \n",
    "        assert model_type in ['regression', 'classification']\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if weights is None:\n",
    "            self.weights = [self.init_function(layers[i-1], layers[i]) for i in range(1, self.num_layers)]\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        \n",
    "        if biases is None:\n",
    "            self.biases = [self.init_function(layers[i]) for i in range(1, self.num_layers)]\n",
    "        else:\n",
    "            self.biases = biases\n",
    "        \n",
    "        if activations is None:\n",
    "            if self.model_type == 'regression':\n",
    "                self.activations = ['sigmoid' for i in range(1, self.num_layers - 1)] + ['linear']\n",
    "            elif self.model_type == 'classification':\n",
    "                self.activations = ['sigmoid' for i in range(1, self.num_layers - 1)] + ['softmax']\n",
    "        else:\n",
    "            self.activations = activations\n",
    "        \n",
    "        activation_functions = {\n",
    "            'sigmoid': self._sigmoid,\n",
    "            'linear': self._linear,\n",
    "            'softmax': self._softmax,\n",
    "            'tanh': self._tanh,\n",
    "            'relu': self._relu\n",
    "        }\n",
    "        self.activation_funcs = list(map(lambda x: activation_functions.get(x), self.activations))\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def _linear(self, z):\n",
    "        return z\n",
    "    \n",
    "    def _tanh(self, z):\n",
    "        return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "    \n",
    "    def _relu(self, z):\n",
    "        return np.maximum(z, 0)\n",
    "    \n",
    "    def _softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / exp_z.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    def tanh_derivative(self, a):\n",
    "        \"\"\"calculates tanh'(z) where a = tanh(z)\"\"\"\n",
    "        return 1 - (a ** 2)\n",
    "    \n",
    "    def sigmoid_derivative(self, a):\n",
    "        \"\"\"calculates sigm'(z) where a = sigm(z)\"\"\"\n",
    "        return a * (1-a)\n",
    "    \n",
    "    def relu_derivative(self, z):\n",
    "        return np.maximum(0, np.sign(z))\n",
    "    \n",
    "    def xavier_init(self, n_in, n_out=None):\n",
    "        if n_out is None:\n",
    "            n_out = n_in\n",
    "            variance = 1 / n_out\n",
    "            stddev = np.sqrt(variance)\n",
    "            return np.random.normal(0, stddev, n_out)\n",
    "        variance = 2 / (n_in + n_out)\n",
    "        stddev = np.sqrt(variance)\n",
    "        return np.random.normal(0, stddev, (n_in, n_out))\n",
    "        \n",
    "    def he_init(self, n_in, n_out=None):\n",
    "        if n_out is None:\n",
    "            variance = 2 / n_in\n",
    "            stddev = np.sqrt(variance)\n",
    "            return np.random.normal(0, stddev, n_in)\n",
    "        variance = 2 / n_in\n",
    "        stddev = np.sqrt(variance)\n",
    "        return np.random.normal(0, stddev, (n_in, n_out))\n",
    "    \n",
    "    def zeros_init(self, n_in, n_out=None):\n",
    "        if n_out is None:\n",
    "            return np.zeros(n_in)\n",
    "        return np.zeros((n_in, n_out))\n",
    "    \n",
    "    def uniform_init(self, n_in, n_out=None):\n",
    "        if n_out is None:\n",
    "            return np.random.uniform(0, 1, n_in)\n",
    "        return np.random.uniform(0, 1, (n_in, n_out))\n",
    "    \n",
    "    def feedforward(self, a, return_activations=False):\n",
    "        if return_activations:\n",
    "            activations = [a]\n",
    "            for w, b, func in zip(self.weights, self.biases, self.activation_funcs):\n",
    "                z = np.dot(a, w) + b\n",
    "                a = func(z)\n",
    "                activations.append(a)\n",
    "            return activations\n",
    "        else:\n",
    "            for w, b, func in zip(self.weights, self.biases, self.activation_funcs):\n",
    "                z = np.dot(a, w) + b\n",
    "                a = func(z)\n",
    "            return a\n",
    "    \n",
    "    def predict(self, X, label=False):\n",
    "        \"\"\" if to use label_predictions function \"\"\"\n",
    "        if label:\n",
    "            return label_predictions(self.feedforward(X))\n",
    "        else:\n",
    "            return self.feedforward(X)\n",
    "    \n",
    "    def mse(self, X, y, resize=False, denormalize=None):\n",
    "        \"\"\"\n",
    "        first predictions are made, then denormalized and then mse is calculated\n",
    "        \n",
    "        denormalize - a tuple (mean, std)\n",
    "        \"\"\"\n",
    "        if resize:\n",
    "            X = X.to_numpy().reshape(-1, 1)\n",
    "            y = y.to_numpy().reshape(-1, 1)\n",
    "        predictions = self.predict(X)\n",
    "        if denormalize:\n",
    "            predictions = destandardize_data(predictions, denormalize)\n",
    "        return np.mean((predictions - y) ** 2)\n",
    "    \n",
    "    def f1_score(self, X, y_true, average='weighted'):\n",
    "        \"\"\"\n",
    "        calculates f1 score. \n",
    "        y_true : 2 dimensional array with probabilities\n",
    "        average: 'weighted', 'macro'\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        y_pred = label_predictions(predictions)\n",
    "        y_true = label_predictions(y_true)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        return f1\n",
    "\n",
    "    def cross_entropy(self, X, y):\n",
    "        \"\"\" Calculates cross entropy loss \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        epsilon = 1e-9  # Small constant to avoid taking the logarithm of zero\n",
    "        return -np.mean(np.sum(y * np.log(predictions + epsilon), axis=1))\n",
    "    \n",
    "    def loss(self, X, y, resize=False, denormalize=None, test=False):\n",
    "        \"\"\" returns appriopriate loss \"\"\"\n",
    "        if self.model_type == 'regression':\n",
    "            return self.mse(X, y, resize=resize, denormalize=denormalize)\n",
    "        elif self.model_type == 'classification':\n",
    "            if test:\n",
    "                return self.f1_score(X, y)\n",
    "            else:\n",
    "                return self.cross_entropy(X, y)\n",
    "\n",
    "    def fitness(self, denormalize):\n",
    "        return self.loss(self.X, self.y, denormalize=denormalize)\n",
    "    \n",
    "    def flatten_weights(self):\n",
    "        \"\"\" flattens weights and biases \"\"\"\n",
    "        flat = []\n",
    "        for weights, biases in zip(self.weights, self.biases):\n",
    "            flat.extend(weights.flatten())\n",
    "            flat.extend(biases.flatten())\n",
    "        return flat\n",
    "    \n",
    "    def unflatten_weights(self, flat):\n",
    "        \"\"\" unflattens flat array of weights and biases \"\"\"\n",
    "        weights_full = []\n",
    "        biases_full = []\n",
    "        \n",
    "        for weights, biases in zip(self.weights, self.biases):\n",
    "            w_len = len(weights.flatten())\n",
    "            b_len = len(biases.flatten())\n",
    "            \n",
    "            w_flat = flat[:w_len]\n",
    "            w_unflat = np.array(w_flat).reshape(weights.shape)\n",
    "            weights_full.append(w_unflat)\n",
    "            flat = flat[w_len:]\n",
    "            \n",
    "            b_flat = flat[:b_len]\n",
    "            b_unflat = np.array(b_flat).reshape(biases.shape)\n",
    "            biases_full.append(b_unflat)\n",
    "            flat = flat[b_len:]\n",
    "        \n",
    "        return weights_full, biases_full\n",
    "    \n",
    "def standardize_data(X):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_new - standardized X\n",
    "    a tuple (mean, std) - normal distribution parameters from X for destandarizing\n",
    "    \"\"\"\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    X_new = (X - mean) / std\n",
    "    return X_new, (mean, std)\n",
    "\n",
    "def destandardize_data(X, parameters):\n",
    "    \"\"\"parameters: a tuple (mean, std)\"\"\"\n",
    "    return X * parameters[1] + parameters[0]\n",
    "\n",
    "\n",
    "def label_predictions(y_pred, class_order=None):\n",
    "    \"\"\"\n",
    "    y_pred : 2 dimensional array\n",
    "    class_order : default [..., 2, 1, 0]\n",
    "    \"\"\"\n",
    "    if class_order is None:\n",
    "        class_order = np.array(range(len(y_pred[0])))\n",
    "    max_indices = np.argmax(y_pred, axis=1)\n",
    "    return class_order[max_indices]\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    \"\"\" y : pd.Series \"\"\"\n",
    "    return pd.get_dummies(y, dtype=int).to_numpy()\n",
    "\n",
    "def decode_array(array):\n",
    "    \"\"\" decodes one hot encoded array \"\"\"\n",
    "    decoded_indices = np.argmax(array, axis=1)\n",
    "    return decoded_indices.tolist()\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    \"\"\" calculated mse \"\"\"\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    \"\"\" calculates cross entropy loss, y_true and y_pred should be 2-dimensional \"\"\"\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "78b57e2d-3a0e-4dab-af5a-64e6af94fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoAlg:\n",
    "    \n",
    "    def __init__(self, X, y, layers, model_type, population_size, denormalize=None, generations=100):\n",
    "        self.default_mlp = NeuralNetwork(layers=layers, X=X, y=y, model_type=model_type)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.layers = layers\n",
    "        self.model_type = model_type\n",
    "        self.denormalize = denormalize\n",
    "        self.dimension = len(self.default_mlp.flatten_weights())\n",
    "        self.population_size = population_size\n",
    "        self.population = np.array([NeuralNetwork(layers=layers, X=X, y=y, model_type=model_type) for i in range(population_size)])\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = None\n",
    "        self.crossover_rate = None\n",
    "    \n",
    "    def point_crossover(self, parent1, parent2):\n",
    "        if np.random.rand() < self.crossover_rate:\n",
    "            point = np.random.randint(1, self.dimension)\n",
    "            \n",
    "            parent1_flat = parent1.flatten_weights()\n",
    "            parent2_flat = parent2.flatten_weights()\n",
    "            \n",
    "            child1_flat = np.concatenate((parent1_flat[:point], parent2_flat[point:]))\n",
    "            child2_flat = np.concatenate((parent2_flat[:point], parent1_flat[point:]))\n",
    "\n",
    "            child1_weights, child1_biases = parent1.unflatten_weights(child1_flat)\n",
    "            child2_weights, child2_biases = parent2.unflatten_weights(child2_flat)\n",
    "\n",
    "            # child1 = NeuralNetwork(layers=self.layers, X=self.X, y=self.y, model_type=self.model_type)\n",
    "            # child2 = NeuralNetwork(layers=self.layers, X=self.X, y=self.y, model_type=self.model_type)\n",
    "            child1 = deepcopy(self.default_mlp)\n",
    "            child2 = deepcopy(self.default_mlp)\n",
    "            \n",
    "            child1.weights = child1_weights\n",
    "            child1.biases = child1_biases\n",
    "            child2.weights = child2_weights\n",
    "            child2.biases = child2_biases\n",
    "            \n",
    "            return child1, child2\n",
    "        return parent1, parent2\n",
    "    \n",
    "    def gaussian_mutation(self, individual):\n",
    "        if np.random.rand() < self.mutation_rate:\n",
    "            \n",
    "            ind_flat = np.array(individual.flatten_weights())\n",
    "            ind_flat += np.random.normal(0, 1, self.dimension)\n",
    "            ind_weights, ind_biases = individual.unflatten_weights(ind_flat)\n",
    "            new_ind = deepcopy(individual)\n",
    "            new_ind.weights = ind_weights\n",
    "            new_ind.biases = ind_biases\n",
    "            return new_ind\n",
    "            \n",
    "        return individual\n",
    "    \n",
    "    def evaluation(self, population):\n",
    "        return np.array([ind.fitness(denormalize=self.denormalize) for ind in population])\n",
    "    \n",
    "    def wheel_selection(self, population, size=None):\n",
    "        if size is None:\n",
    "            size = self.population_size\n",
    "        fitness = self.evaluation(population)\n",
    "        fitness_inverted = 1 / fitness\n",
    "        probabilities = fitness_inverted / np.sum(fitness_inverted)\n",
    "        selected_indices = np.random.choice(len(population), size, p=probabilities)\n",
    "        # print(selected_indices)\n",
    "        return population[selected_indices]\n",
    "    \n",
    "    def choose_random_individuals(self, population_size, n):\n",
    "        individuals = self.population[np.random.choice(population_size, n, replace=False)]\n",
    "        if n == 1:\n",
    "            return individuals[0]\n",
    "        else:\n",
    "            return individuals\n",
    "    \n",
    "    def train(self, mutation_rate=0.1, crossover_rate=0.7, mute_print=False):\n",
    "        \n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        \n",
    "        best_fitness_history = []\n",
    "        \n",
    "        for generation in range(self.generations):\n",
    "\n",
    "            new_population = []\n",
    "            while len(new_population) < self.population_size: # -> hiperparametr\n",
    "            # for i in range(int(self.population_size / 2)):\n",
    "                parent1, parent2 = self.choose_random_individuals(self.population_size, 2)\n",
    "                child1, child2 = self.point_crossover(parent1, parent2)\n",
    "                new_population.extend([child1, child2])\n",
    "            # population = population.extend(new_population)\n",
    "            population = np.vstack([self.population, np.array(new_population)]).flatten()\n",
    "            \n",
    "            new_population = []\n",
    "            for i, parent in enumerate(population):\n",
    "                child = self.gaussian_mutation(parent)\n",
    "                new_population.extend([child])\n",
    "                # population[i] = child\n",
    "            population = np.vstack([population, np.array(new_population)]).flatten()\n",
    "            # dodać zmutowane\n",
    "            \n",
    "            fitness = self.evaluation(population)\n",
    "\n",
    "            # Number of top individuals to retain\n",
    "            num_top_individuals = max(1, int(0.1 * len(population)))\n",
    "        \n",
    "            # Get indices of the individuals sorted by their fitness (ascending)\n",
    "            sorted_indices = np.argsort(fitness)\n",
    "        \n",
    "            # Retain the top 10% individuals\n",
    "            top_individuals = population[sorted_indices[:num_top_individuals]]\n",
    "        \n",
    "            # Apply wheel selection to the rest of the population\n",
    "            remaining_population = self.wheel_selection(population, size=self.population_size - num_top_individuals)\n",
    "        \n",
    "            # Combine the top individuals with the selected individuals from the remaining population\n",
    "            self.population = np.concatenate((top_individuals, remaining_population))\n",
    "        \n",
    "            # Update the fitness and the best individual\n",
    "            fitness = self.evaluation(self.population)\n",
    "            best_individual = self.population[np.argmin(fitness)]\n",
    "            best_fitness = best_individual.fitness(self.denormalize)\n",
    "            \n",
    "            # self.population = self.wheel_selection(population)\n",
    "            \n",
    "            # fitness = self.evaluation(self.population)\n",
    "            # best_individual = self.population[np.argmin(fitness)]\n",
    "            # best_fitness = best_individual.fitness()\n",
    "            # zostwic top 10%\n",
    "            best_fitness_history.append(best_fitness)\n",
    "            if not mute_print:\n",
    "                print(f\"Generation {generation+1}: best individual: {best_individual}, fitness: {best_fitness}\")\n",
    "        \n",
    "        if mute_print:\n",
    "            print(f\"Best individual: {best_individual}, fitness: {best_fitness}\")\n",
    "        history = History(best_fitness_history)\n",
    "        return history, (best_individual, best_fitness)\n",
    "    \n",
    "class History:\n",
    "    \n",
    "    def __init__(self, fitness):\n",
    "        self.fitness = fitness\n",
    "        self.generations = list(range(len(fitness)))\n",
    "    \n",
    "    def plot_history(self):\n",
    "        plt.plot(self.generations, self.fitness)\n",
    "        plt.ylabel(\"Best individual fitness\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.title(\"Evolution history\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cb39b380-f834-4e80-af1b-78295dd522a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm_modal, parameters_modal = standardize_data(multimodal['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "61ab9bf2-b658-40f5-8693-a0718baeb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = EvoAlg(X=multimodal['x'], y=y_norm_modal, denormalize=parameters_modal, layers=[1,10,1], model_type='regression',\n",
    "            population_size=20, generations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cdd921a4-ed55-4975-a7bb-cccfe3f3909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: best individual: <__main__.NeuralNetwork object at 0x000001D55840D050>, fitness: 218.99462670449228\n",
      "Generation 2: best individual: <__main__.NeuralNetwork object at 0x000001D558BB3890>, fitness: 72.50842603534781\n",
      "Generation 3: best individual: <__main__.NeuralNetwork object at 0x000001D558BB3890>, fitness: 72.50842603534781\n",
      "Generation 4: best individual: <__main__.NeuralNetwork object at 0x000001D558BB3890>, fitness: 72.50842603534781\n",
      "Generation 5: best individual: <__main__.NeuralNetwork object at 0x000001D558872D10>, fitness: 50.137228361659304\n",
      "Generation 6: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 7: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 8: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 9: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 10: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 11: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 12: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 13: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 14: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 15: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 16: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 17: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 18: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 19: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 20: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 21: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 22: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 23: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 24: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 25: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 26: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 27: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 28: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 29: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 30: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 31: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 32: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 33: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 34: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 35: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 36: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 37: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 38: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 39: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 40: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 41: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 42: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 43: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 44: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 45: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 46: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 47: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 48: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 49: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n",
      "Generation 50: best individual: <__main__.NeuralNetwork object at 0x000001D559D3A6D0>, fitness: 40.62181172782724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.History at 0x1d55a579110>,\n",
       " (<__main__.NeuralNetwork at 0x1d559d3a6d0>, 40.62181172782724))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f7b9f9-45e9-4b30-889b-b6b73c56fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal = pd.read_csv(\"dane/multimodal-large-training.csv\", index_col=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d632e95f-2dcb-4301-9df9-382542291e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.685726</td>\n",
       "      <td>-74.197483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.879898</td>\n",
       "      <td>-30.504177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.411932</td>\n",
       "      <td>10.754122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.688954</td>\n",
       "      <td>100.248297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.573238</td>\n",
       "      <td>-73.832310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.194391</td>\n",
       "      <td>44.275897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.012924</td>\n",
       "      <td>100.169387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.569789</td>\n",
       "      <td>-93.553272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.538241</td>\n",
       "      <td>-96.450956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-0.390941</td>\n",
       "      <td>-24.352178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x           y\n",
       "0    -0.685726  -74.197483\n",
       "1    -0.879898  -30.504177\n",
       "2     1.411932   10.754122\n",
       "3     1.688954  100.248297\n",
       "4    -0.573238  -73.832310\n",
       "...        ...         ...\n",
       "9995 -0.194391   44.275897\n",
       "9996  1.012924  100.169387\n",
       "9997  0.569789  -93.553272\n",
       "9998  0.538241  -96.450956\n",
       "9999 -0.390941  -24.352178\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329c7e5-a91f-41ae-807d-d3b486a4086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __init__(self, X, y, layers, model_type, population_size, generations=100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4fb678a-c78d-4435-95f2-93b21206d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee0755b3-6d0c-46ea-8a58-6a7bde76bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NeuralNetwork([1, 5, 5, 1], multimodal['x'], multimodal['y'], model_type='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b445cd9b-b58b-4770-a265-cb32206b384d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5369.088791491285"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.mse(multimodal['x'], multimodal['y'], resize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9bc9c7b-021d-48eb-8200-f7a7dcf8eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = mlp.flatten_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe394963-9e11-45fc-96e1-d77582e1adaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.70004499,  0.52552866, -1.29394331,  1.02121036, -0.78481941]]),\n",
       " array([[ 0.28908235, -0.00997967,  0.17720337,  0.35732718, -0.17456391],\n",
       "        [-0.56095764, -0.11253742,  0.2139857 , -0.29504541,  0.20333845],\n",
       "        [-0.56179019, -0.59112699,  0.11949727, -0.94020714,  0.16769898],\n",
       "        [-0.11263718, -0.87777692, -0.86608131, -0.35686873, -0.02388226],\n",
       "        [ 0.01145561,  0.68650088,  0.88771622, -0.33011953, -0.23520118]]),\n",
       " array([[-1.15392248],\n",
       "        [-0.03544772],\n",
       "        [ 0.62856561],\n",
       "        [ 0.25814476],\n",
       "        [ 1.2643477 ]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dca198f6-000b-42f4-b30e-f86e894444bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.70004499,  0.52552866, -1.29394331,  1.02121036, -0.78481941]]),\n",
       " array([[ 0.28908235, -0.00997967,  0.17720337,  0.35732718, -0.17456391],\n",
       "        [-0.56095764, -0.11253742,  0.2139857 , -0.29504541,  0.20333845],\n",
       "        [-0.56179019, -0.59112699,  0.11949727, -0.94020714,  0.16769898],\n",
       "        [-0.11263718, -0.87777692, -0.86608131, -0.35686873, -0.02388226],\n",
       "        [ 0.01145561,  0.68650088,  0.88771622, -0.33011953, -0.23520118]]),\n",
       " array([[-1.15392248],\n",
       "        [-0.03544772],\n",
       "        [ 0.62856561],\n",
       "        [ 0.25814476],\n",
       "        [ 1.2643477 ]])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = mlp.unflatten_weights(flat)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b5293a-9632-4e97-bfd5-746bb7ddf5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"iris.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d472df4-d184-4f2b-94cc-8f356984d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# struktura algorytmu ewolucyjnego"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
