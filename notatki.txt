ocenianie: kryteria + zakres/różnorodność eksperymentów
znormalizować -> nauczyć -> odnormalizować -> liczyć MSE
nie tworzyć dużych sieci
numpy, einops
nnanddl.com

NN1
-----
5 neuronów działa -> w większych architekturach zerowanie pozostałych neronów 
wysokie wagi, dodawanie funkcji sigmoidalnych

dane wielowymiarowe
X e R(n x 2)
W1 e R(2 x 3) przechodzimy z dwóch do trzech neuronów


NN2
-----
wykres batchowy, różne rozmiary, dla każdego zbioru (mse od liczby epok)
eksperymenty w zależności od kroku uczenia, inicjalizacji
znaleźć wagi spełniające progi punktowe


NN3
-----
wcześniej:
p = p - lambda * dc/dp

z momentem: 
v(t) = v(t-1) + a * dc/dp  (dostęp w kolejnych iteracjach)
p = p - lambda * v(t)

rmsProp:
MS(p,t) = alfa*MS(p, t-1) + (1-alfa)*(dc/dp)^2
interpretacja - alfa mówi ile będziemy wykorzystywać z wcześniej, a ile z nowo obliczonych
p = p - lambda (1 / sqrt(MS(p,t) + e)) * dc/dp (dc/dp już uśrednione w danym batchu)
mały krok uczenia

wykres:
oś x - batche
oś y - mse
linia dla backpropgacji, momentu, rmsprop
taki wykres dla każdego zbioru danych

threshold dla któregokolwiek typu zbieżności

NN4
-----
liczba klas - liczba neuronów wyjściowych
wartość neuronu to p-stwo przynależności do danej klasy

funkcja softmax:
S(z) nalezy do (0,1)
suma(S(z_j)) = 1

cross-entropy loss
C(s,p) = -suma( p_i * log(s_i) ) 

w przypadku 2 klas i one hot encodingu p to jest [1 0] lub [0 1]

zdjecie tablicy -_-

implementacja f-score (wybrac sposob usredniania)

NN5
-----
liniowa:
nie nadaje się

sigmoid:
(0,1)
max(f'(x)) = 0.25

tanh:
f(x) = tanh(x) = 2*sigmoid(2x)-1
(-1, 1)
f'(x) = 1 - tanh^2(x)
max(f'(x)) = 1

relu:
f(x) = 0 (x<=0) , x (x>0) = max(0,x)
f'(x) = 0 (x<=0) , 1 (x>0) = max(0, sign(x)) ??

eksperymentować z aktywacjami na ukrytych warstwach
(ostatnią funkcję aktywacji dobrać do problemu który rozwiązujemy)

testować architektury, zmieniamy liczbę warstw (chcemy wykryc problem zanikajcego gradientu)

wykresy dla każego typu architektury (1,2,3 warstwy) i dla każdego zbioru 
- funkcja kosztu od liczby epok
- po jednej linii typu aktywacji
- uśrednić linie + przedział ufności

RAPORT
-----
podział na labki
jakie eksperymenty, wyniki, wykresy
analiza - co wyszło z eksperymentów, wnioski

wszystkie wyniki, konfiguracje

batch_size = eksperyment z klasyfikacją easy i batch_size = 1